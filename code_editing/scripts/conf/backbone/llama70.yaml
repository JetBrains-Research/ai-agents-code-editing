defaults:
  - base_hf
  - _self_

model_name: "codellama/CodeLlama-70b-Instruct-hf"
is_encoder_decoder: false
model_kwargs:
  load_in_4bit: true
  attn_implementation: "flash_attention_2"
